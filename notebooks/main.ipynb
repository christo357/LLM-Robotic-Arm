{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdd62231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import gymnasium as gym\n",
    "import gymnasium_robotics\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from sb3_contrib import TQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "817d59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from multi_fetch_env import MultiObjectFetchPickAndPlaceEnv\n",
    "import my_envs\n",
    "from wrappers import ActiveObjectWrapper\n",
    "\n",
    "gym.register_envs(gymnasium_robotics)\n",
    "\n",
    "LOG_DIR = 'logs_testing'\n",
    "# RUN_ID = os.getenv('RESUME_ID', None)\n",
    "# assert RUN_ID is not None,  \"Set RESUME_ID to the run folder name (e.g., 08vger36)\"\n",
    "\n",
    "ENV_ID = 'MultiObjectFetchPickAndPlace-v0'\n",
    "# MultiObjectFetchPickAndPlace-v0\n",
    "\n",
    "# ENV_ID = 'FetchPickAndPlace-v4'\n",
    "MODEL_PATH = os.path.join('models', 'tqcdense_model.zip')\n",
    "VECNORM_PATH = os.path.join('models', 'tqcdense_vecnorm.pkl')\n",
    "VIDEO_DIR = os.path.join(LOG_DIR, \"inference_videos\")\n",
    "\n",
    "\n",
    "def make_eval_env():\n",
    "    env = gym.make(\n",
    "        ENV_ID,\n",
    "        render_mode = 'human', \n",
    "        reward_type = 'dense', \n",
    "        max_episode_steps=50, \n",
    "        n_objects = 4\n",
    "    )\n",
    "    # os.makedirs(VIDEO_DIR, exist_ok=True)\n",
    "\n",
    "    # env = RecordVideo(\n",
    "    #     env,\n",
    "    #     video_folder=VIDEO_DIR,\n",
    "    #     episode_trigger=lambda ep: True,  # record every episode\n",
    "    #     name_prefix=\"eval\",\n",
    "    # )\n",
    "    env = ActiveObjectWrapper(env, 0, 5)\n",
    "    # env = Monitor(env)  # for episode stats\n",
    "    \n",
    "    return env\n",
    "\n",
    "eval_env = DummyVecEnv([make_eval_env])\n",
    "\n",
    "if os.path.exists(VECNORM_PATH):\n",
    "    eval_env = VecNormalize.load(VECNORM_PATH, eval_env)\n",
    "else:\n",
    "    raise FileNotFoundError(f'Missing Vecnormalize file : {VECNORM_PATH}')\n",
    "\n",
    "eval_env.training = False\n",
    "eval_env.norm_reward = False\n",
    "\n",
    "model = TQC.load(MODEL_PATH, env = eval_env)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1415483f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ActiveObjectWrapper' object has no attribute '_get_obs'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 165\u001b[39m\n\u001b[32m    162\u001b[39m eval_env.env_method(\u001b[33m\"\u001b[39m\u001b[33mset_active_object\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    164\u001b[39m target = np.array([\u001b[32m1.45\u001b[39m, \u001b[32m0.75\u001b[39m, \u001b[32m0.45\u001b[39m]) \u001b[38;5;66;03m# Example Shelf\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m \u001b[43msurgical_routine\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36msurgical_routine\u001b[39m\u001b[34m(vec_env, model, final_target)\u001b[39m\n\u001b[32m     19\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mActiveObjectWrapper not found in env stack!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Setup Waypoints (using raw env to get initial positions)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m initial_obs = \u001b[43mraw_env\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_obs\u001b[49m() \u001b[38;5;66;03m# Get raw dict (meters)\u001b[39;00m\n\u001b[32m     23\u001b[39m obj_pos = initial_obs[\u001b[33m'\u001b[39m\u001b[33mobservation\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m3\u001b[39m:\u001b[32m6\u001b[39m].copy()\n\u001b[32m     24\u001b[39m final_target = obj_pos = initial_obs[\u001b[33m'\u001b[39m\u001b[33mdesired_goal\u001b[39m\u001b[33m'\u001b[39m].copy()\n",
      "\u001b[31mAttributeError\u001b[39m: 'ActiveObjectWrapper' object has no attribute '_get_obs'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "\n",
    "def surgical_routine(vec_env, model, final_target):\n",
    "    # 1. Reset Standard Wrapper\n",
    "    # This initializes the wrappers (Monitor, VideoRecorder, etc.) correctly\n",
    "    vec_env.reset()\n",
    "    \n",
    "    # 2. Access 'Unwrapped' for Physics/Logic checks (Read-Only)\n",
    "    # We use this to know where things *really* are in meters\n",
    "    env_stack = vec_env.envs[0] #.unwrapped\n",
    "    \n",
    "    raw_env = env_stack\n",
    "    while not hasattr(raw_env, \"set_active_object\"):\n",
    "        if hasattr(raw_env, \"env\"):\n",
    "            raw_env = raw_env.env\n",
    "        else:\n",
    "            raise ValueError(\"ActiveObjectWrapper not found in env stack!\")\n",
    "    \n",
    "    # Setup Waypoints (using raw env to get initial positions)\n",
    "    initial_obs = raw_env._get_obs() # Get raw dict (meters)\n",
    "    obj_pos = initial_obs['observation'][3:6].copy()\n",
    "    final_target = obj_pos = initial_obs['desired_goal'].copy()\n",
    "    # print(final_target).exit()\n",
    "    \n",
    "    hover_point = obj_pos.copy()\n",
    "    hover_point[2] += 0.10  # 25cm above\n",
    "    \n",
    "    state = \"HOVER\"\n",
    "    gripper_closed = False \n",
    "    # open_grip = False\n",
    "    \n",
    "    print(f\"--- Starting Surgical Routine ---\")\n",
    "    \n",
    "    while True:\n",
    "        # --- A. READ REALITY ---\n",
    "        # Get a fresh RAW observation from the internal physics\n",
    "        # We do this every step to get the latest coordinates in meters\n",
    "        raw_obs = raw_env._get_obs()\n",
    "        current_grip = raw_obs['observation'][:3]\n",
    "        current_obj  = raw_obs['observation'][3:6]\n",
    "        \n",
    "        # --- B. STATE MACHINE (Decide the Goal) ---\n",
    "        # We modify 'raw_obs' to trick the agent into doing what we want\n",
    "        \n",
    "        if state == \"HOVER\":\n",
    "            # TRICK: Tell agent \"I am already holding the object\"\n",
    "            # Set Object Pos = Gripper Pos. \n",
    "            # This makes the policy drive the Gripper to the Goal.\n",
    "            # raw_obs['observation'][3:6] = current_grip\n",
    "            # raw_obs['observation'][6:9] = [0, 0, 0] # Relative dist is 0\n",
    "            \n",
    "            # STRATEGY: \"The Ghost Object\"\n",
    "            # We tell the agent the object is AT the hover point.\n",
    "            # The agent will try to fly there to \"pick it up\".\n",
    "            \n",
    "            # 1. Lie: Object is at Hover Point\n",
    "            raw_obs['observation'][3:6] = hover_point\n",
    "            # 2. Lie: Relative Distance = Hover Point - Current Gripper\n",
    "            # (Standard subtraction the agent expects)\n",
    "            raw_obs['observation'][6:9] = raw_obs['observation'][3:6] - current_grip\n",
    "            # Set Goal = Hover Point\n",
    "            raw_obs['desired_goal'] = hover_point\n",
    "            \n",
    "            # Force Gripper Open (Agent expects open gripper during approach)\n",
    "            override_gripper = 1.0\n",
    "            \n",
    "            # Check success (in meters)\n",
    "            dist = np.linalg.norm(current_grip - hover_point)\n",
    "            print(f'dist:{dist} ; grip_pos: {current_grip} ; hover: {hover_point}')\n",
    "\n",
    "            if dist < 0.05:\n",
    "                print(\">> Hover Reached. Descending...\")\n",
    "                state = \"DESCEND\"\n",
    "\n",
    "        elif state == \"DESCEND\":\n",
    "            # # TRICK: Still pretend we hold it, but move goal to object\n",
    "            # raw_obs['observation'][3:6] = current_grip\n",
    "            # raw_obs['observation'][6:9] = [0, 0, 0]\n",
    "            \n",
    "            # Goal = The real object position\n",
    "            raw_obs['desired_goal'] = obj_pos\n",
    "            \n",
    "            override_gripper = 1.0\n",
    "            \n",
    "            # Check proximity to grasp\n",
    "            dist = np.linalg.norm(current_grip - obj_pos)\n",
    "            if dist < 0.03: # Very close\n",
    "                print(\">> In Position. Grasping...\")\n",
    "                state = \"GRASP\"\n",
    "\n",
    "        elif state == \"GRASP\":\n",
    "            # REALITY: Give the agent the TRUE observation now.\n",
    "            # It sees the object right in front of it and will naturally close gripper.\n",
    "            # raw_obs['desired_goal'] = obj_pos\n",
    "             \n",
    "            override_gripper = -1.0\n",
    "            # We can force the gripper closed in the action later, \n",
    "            # or trust the agent. TQC usually closes instantly here.\n",
    "            \n",
    "            # Check if lifted (Z height increased)\n",
    "            if current_obj[2] > obj_pos[2] + 0.02:\n",
    "                print(\">> Object Moving! Lifting...\")\n",
    "                state = \"MOVE\"\n",
    "\n",
    "        # elif state == \"LIFT\":\n",
    "        #     # REALITY: Object is held. Set Goal High.\n",
    "        #     lift_target = obj_pos.copy()\n",
    "        #     lift_target[2] += 0.4\n",
    "        #     raw_obs['desired_goal'] = lift_target\n",
    "            \n",
    "        #     if current_obj[2] > obj:\n",
    "        #         print(\">> Lifted. Moving to Drop...\")\n",
    "        #         state = \"MOVE\"\n",
    "\n",
    "        elif state == \"MOVE\":\n",
    "            # REALITY: Set Goal to Final Target\n",
    "            raw_obs['desired_goal'] = final_target\n",
    "            \n",
    "            dist = np.linalg.norm(current_obj - final_target)\n",
    "            if dist < 0.05:\n",
    "                print(\">> MISSION COMPLETE\")\n",
    "                break\n",
    "\n",
    "        # --- C. NORMALIZE MANUALLY ---\n",
    "        # The model needs Normalized data. We use the wrapper to convert our\n",
    "        # hacked raw_obs into something the model understands.\n",
    "        \n",
    "        # 1. Add Batch Dimension (VecEnv expects (1, Dim))\n",
    "        obs_vec = {key: val[np.newaxis, ...] for key, val in raw_obs.items()}\n",
    "        \n",
    "        # 2. Normalize using the Env's running stats\n",
    "        # This is the \"Magic\" bridge between your Meter logic and the Agent's Sigma logic\n",
    "        obs_norm = vec_env.normalize_obs(obs_vec)\n",
    "        \n",
    "        # --- D. PREDICT & STEP ---\n",
    "        # Predict using our crafted input\n",
    "        action, _ = model.predict(obs_norm, deterministic=True)\n",
    "        \n",
    "        # Optional: Manual Gripper Override (Safety)\n",
    "        # If we are in Hover/Descend, force Open (1.0)\n",
    "        # If we are in Lift/Move, force Closed (-1.0)\n",
    "        # if state in [\"HOVER\", \"DESCEND\"]:\n",
    "        # if open_grip:\n",
    "        #     action[0, 3] = 1.0\n",
    "        #     open_grip=False\n",
    "        # elif state in [\"LIFT\", \"MOVE\"]:\n",
    "        #     action[0, 3] = -1.0\n",
    "\n",
    "        # Execute standard step (maintains recording, timing, rendering)\n",
    "        # We discard the 'obs' returned here because we generate our own next loop\n",
    "        _, _, done, info = vec_env.step(action)\n",
    "        \n",
    "        time.sleep(0.02)\n",
    "        vec_env.render()\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "# Run it\n",
    "eval_env.env_method(\"set_active_object\", 2)\n",
    "\n",
    "target = np.array([1.45, 0.75, 0.45]) # Example Shelf\n",
    "surgical_routine(eval_env, model, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0be13006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Surgical Routine ---\n",
      "dist:0.09679288247314226 ; grip_pos: [1.34193475 0.74910105 0.53472519] ; hover: [1.2652443  0.69360772 0.55492239]\n",
      "dist:0.09270660050753887 ; grip_pos: [1.31115907 0.77366754 0.5636844 ] ; hover: [1.2652443  0.69360772 0.55492239]\n",
      "dist:0.056985097231171275 ; grip_pos: [1.28377786 0.74543069 0.5696936 ] ; hover: [1.2652443  0.69360772 0.55492239]\n",
      "dist:0.019309433710078733 ; grip_pos: [1.26777152 0.71227603 0.55068427] ; hover: [1.2652443  0.69360772 0.55492239]\n",
      ">> Hover Reached. Descending...\n",
      ">> In Position. Grasping...\n",
      ">> Object Moving! Lifting...\n",
      ">> Lifted Safe (Z=0.61). Moving to Target...\n",
      ">> MISSION COMPLETE\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "\n",
    "def surgical_routine(vec_env, model, final_target):\n",
    "    # 1. Reset Standard Wrapper\n",
    "    # This initializes the wrappers (Monitor, VideoRecorder, etc.) correctly\n",
    "    vec_env.reset()\n",
    "    \n",
    "    # 2. Access 'Unwrapped' for Physics/Logic checks (Read-Only)\n",
    "    # We use this to know where things *really* are in meters\n",
    "    env_stack = vec_env.envs[0] #.unwrapped\n",
    "    \n",
    "    raw_env = env_stack\n",
    "    while not hasattr(raw_env, \"set_active_object\"):\n",
    "        if hasattr(raw_env, \"env\"):\n",
    "            raw_env = raw_env.env\n",
    "        else:\n",
    "            raise ValueError(\"ActiveObjectWrapper not found in env stack!\")\n",
    "    \n",
    "    # Setup Waypoints (using raw env to get initial positions)\n",
    "    # initial_obs = raw_env._get_obs() # Get raw dict (meters)\n",
    "    raw_obs = raw_env.get_current_obs()\n",
    "    obj_pos_start = raw_obs['observation'][3:6].copy()\n",
    "    final_target = obj_pos = raw_obs['desired_goal'].copy()\n",
    "    # print(final_target).exit()\n",
    "    \n",
    "    hover_point = obj_pos_start.copy()\n",
    "    hover_point[2] += 0.10  # 25cm above\n",
    "    \n",
    "    # Define a Safe Z Height for transporting (e.g., 60cm high)\n",
    "    SAFE_Z_HEIGHT = 0.65\n",
    "    \n",
    "    state = \"HOVER\"\n",
    "    override_gripper = None # Default Open\n",
    "    # open_grip = False\n",
    "    \n",
    "    print(f\"--- Starting Surgical Routine ---\")\n",
    "    \n",
    "    while True:\n",
    "        # --- A. READ REALITY ---\n",
    "        # Get a fresh RAW observation from the internal physics\n",
    "        # We do this every step to get the latest coordinates in meters\n",
    "        raw_obs = raw_env.get_current_obs()\n",
    "        current_grip = raw_obs['observation'][:3]\n",
    "        current_obj  = raw_obs['observation'][3:6]\n",
    "        \n",
    "        # --- B. STATE MACHINE (Decide the Goal) ---\n",
    "        # We modify 'raw_obs' to trick the agent into doing what we want\n",
    "        \n",
    "        if state == \"HOVER\":\n",
    "            \n",
    "            # STRATEGY: \"The Ghost Object\"\n",
    "            # We tell the agent the object is AT the hover point.\n",
    "            # The agent will try to fly there to \"pick it up\".\n",
    "            \n",
    "            # 1. Lie: Object is at Hover Point\n",
    "            raw_obs['observation'][3:6] = hover_point\n",
    "            # 2. Lie: Relative Distance = Hover Point - Current Gripper\n",
    "            # (Standard subtraction the agent expects)\n",
    "            raw_obs['observation'][6:9] = raw_obs['observation'][3:6] - current_grip\n",
    "            # Set Goal = Hover Point\n",
    "            raw_obs['desired_goal'] = hover_point\n",
    "            \n",
    "            # Force Gripper Open (Agent expects open gripper during approach)\n",
    "            # override_gripper = 1.0\n",
    "            \n",
    "            # Check success (in meters)\n",
    "            dist = np.linalg.norm(current_grip - hover_point)\n",
    "            print(f'dist:{dist} ; grip_pos: {current_grip} ; hover: {hover_point}')\n",
    "\n",
    "            if dist < 0.05:\n",
    "                print(\">> Hover Reached. Descending...\")\n",
    "                state = \"DESCEND\"\n",
    "\n",
    "        elif state == \"DESCEND\":\n",
    "            # # TRICK: Still pretend we hold it, but move goal to object\n",
    "            # raw_obs['observation'][3:6] = current_grip\n",
    "            # raw_obs['observation'][6:9] = [0, 0, 0]\n",
    "            \n",
    "            # Goal = The real object position\n",
    "            raw_obs['desired_goal'] = obj_pos_start\n",
    "            \n",
    "            # override_gripper = 1.0\n",
    "            \n",
    "            # Check proximity to grasp\n",
    "            dist = np.linalg.norm(current_grip - obj_pos_start)\n",
    "            if dist < 0.03: # Very close\n",
    "                print(\">> In Position. Grasping...\")\n",
    "                state = \"GRASP\"\n",
    "\n",
    "        elif state == \"GRASP\":\n",
    "            # REALITY: Give the agent the TRUE observation now.\n",
    "            # It sees the object right in front of it and will naturally close gripper.\n",
    "            # raw_obs['desired_goal'] = obj_pos\n",
    "             \n",
    "            override_gripper = -1.0\n",
    "            # We can force the gripper closed in the action later, \n",
    "            # or trust the agent. TQC usually closes instantly here.\n",
    "            \n",
    "            # Check if lifted (Z height increased)\n",
    "            if current_obj[2] > obj_pos_start[2] + 0.02:\n",
    "                print(\">> Object Moving! Lifting...\")\n",
    "                state = \"LIFT\"\n",
    "\n",
    "        elif state == \"LIFT\":\n",
    "            # --- THE NEW ELEVATOR LOGIC ---\n",
    "            \n",
    "            # 1. Trick: \"I have it\" (Object is at Gripper)\n",
    "            raw_obs['observation'][3:6] = current_grip\n",
    "            raw_obs['observation'][6:9] = [0, 0, 0]\n",
    "            \n",
    "            # 2. Goal: LOCK X/Y, INCREASE Z\n",
    "            # We construct a target that is exactly where we are now, but higher.\n",
    "            # This prevents the arm from drifting sideways into neighbors.\n",
    "            elevator_target = current_grip.copy()\n",
    "            elevator_target[2] = SAFE_Z_HEIGHT \n",
    "            \n",
    "            raw_obs['desired_goal'] = elevator_target\n",
    "            \n",
    "            override_gripper = -1.0 # Close\n",
    "            \n",
    "            # 3. Transition: When we are high enough\n",
    "            if current_grip[2] > SAFE_Z_HEIGHT - 0.05:\n",
    "                print(f\">> Lifted Safe (Z={current_grip[2]:.2f}). Moving to Target...\")\n",
    "                state = \"MOVE\"\n",
    "                \n",
    "        elif state == \"MOVE\":\n",
    "            # REALITY: Set Goal to Final Target\n",
    "            raw_obs['desired_goal'] = final_target\n",
    "            override_gripper = -1.0\n",
    "            \n",
    "            dist = np.linalg.norm(current_obj - final_target)\n",
    "            if dist < 0.02:\n",
    "                print(\">> MISSION COMPLETE\")\n",
    "                break\n",
    "\n",
    "        # --- C. NORMALIZE MANUALLY ---\n",
    "        # The model needs Normalized data. We use the wrapper to convert our\n",
    "        # hacked raw_obs into something the model understands.\n",
    "        \n",
    "        # 1. Add Batch Dimension (VecEnv expects (1, Dim))\n",
    "        obs_vec = {key: val[np.newaxis, ...] for key, val in raw_obs.items()}\n",
    "        \n",
    "        # 2. Normalize using the Env's running stats\n",
    "        # This is the \"Magic\" bridge between your Meter logic and the Agent's Sigma logic\n",
    "        obs_norm = vec_env.normalize_obs(obs_vec)\n",
    "        \n",
    "        # --- D. PREDICT & STEP ---\n",
    "        # Predict using our crafted input\n",
    "        action, _ = model.predict(obs_norm, deterministic=True)\n",
    "        \n",
    "        if override_gripper is not None:\n",
    "            action[0, 3] = override_gripper\n",
    "        \n",
    "        _, _, done, info = vec_env.step(action)\n",
    "        \n",
    "        time.sleep(0.02)\n",
    "        vec_env.render()\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "# Run it\n",
    "eval_env.env_method(\"set_active_object\", 3)\n",
    "\n",
    "target = np.array([[1.4, 0.65, 0.43]]) # Example Shelf\n",
    "surgical_routine(eval_env, model, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96b71340",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c115666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import time\n",
    "\n",
    "# def run_surgical_pick_and_place(env, model, final_target):\n",
    "#     # 1. Setup\n",
    "#     obs = eval_env.reset()\n",
    "    \n",
    "#     # Get the REAL position of the object we want to pick\n",
    "#     # We extract this from the observation (indices 3:6 are object pos)\n",
    "#     real_obj_pos = obs['observation'][0, 3:6].copy()\n",
    "#     # print(real_obj_pos)\n",
    "    \n",
    "#     # Define our Waypoints\n",
    "#     hover_point = real_obj_pos.copy()\n",
    "#     print(hover_point)\n",
    "#     hover_point[2] += 0.20  # 20cm above object\n",
    "    \n",
    "#     lift_point = real_obj_pos.copy()\n",
    "#     lift_point[2] += 0.30   # Lift high before moving\n",
    "    \n",
    "#     state = \"HOVER\"\n",
    "#     gripper_closed = False\n",
    "    \n",
    "#     print(f\"--- Starting Sequence for Object  ---\")\n",
    "    \n",
    "#     while True:\n",
    "#         # --- STATE MACHINE LOGIC ---\n",
    "        \n",
    "#         current_gripper_pos = obs['observation'][0, 0:3]\n",
    "        \n",
    "#         if state == \"HOVER\":\n",
    "#             # THE TRICK: Tell agent the object is at the hover point\n",
    "#             # We construct a \"Ghost Observation\"\n",
    "#             ghost_obs = obs.copy()\n",
    "#             ghost_obs['observation'] = obs['observation'].copy()\n",
    "            \n",
    "#             # Fake the object position to be the hover point\n",
    "#             ghost_obs['observation'][0, 3:6] = hover_point.ravel()\n",
    "#             # Fake the relative distance (Ghost - Gripper)\n",
    "#             ghost_obs['observation'][0, 6:9] = hover_point.ravel() - current_gripper_pos\n",
    "            \n",
    "#             # Set the goal to the hover point too, so it thinks it just needs to go there\n",
    "#             ghost_obs['desired_goal'] = np.expand_dims(hover_point.ravel(), axis=0)\n",
    "            \n",
    "            \n",
    "#             # Predict action based on the LIE\n",
    "#             action, _ = model.predict(ghost_obs, deterministic=True)\n",
    "            \n",
    "#             # print(f'action:{action}')\n",
    "#             # Force Gripper OPEN (1.0)\n",
    "            \n",
    "#             # Check if we arrived\n",
    "#             dist = np.linalg.norm(current_gripper_pos - hover_point)\n",
    "#             print(f'dist:{dist} ; grip_pos: {current_gripper_pos} ; hover: {hover_point}')\n",
    "#             if dist < 0.05:\n",
    "#                 print(\">> Hover Reached. Descending...\")\n",
    "#                 state = \"GRASP\"\n",
    "#                 action[0, 3] = 1.0 \n",
    "\n",
    "\n",
    "#         elif state == \"GRASP\":\n",
    "#             # REVEAL THE TRUTH: Use the real observation\n",
    "#             # The agent will naturally try to go to the real object\n",
    "            \n",
    "#             # We allow the agent to decide when to close the gripper, \n",
    "#             # BUT usually TQC is eager. Let's just run the model normally.\n",
    "#             action, _ = model.predict(obs, deterministic=True)\n",
    "            \n",
    "#             # Monitor if the agent has grasped it.\n",
    "#             # (In Fetch, grip state < 0 usually means closing)\n",
    "#             # A simple check: Is the object moving up?\n",
    "#             obj_z = obs['observation'][5] # Z height of object\n",
    "            \n",
    "#             if obj_z > real_obj_pos[2] + 0.05: # If lifted 5cm\n",
    "#                 print(\">> Object Grasped! Lifting...\")\n",
    "#                 state = \"LIFT\"\n",
    "\n",
    "#         elif state == \"LIFT\":\n",
    "#             # Override the Goal to be high up\n",
    "#             obs['desired_goal'] = lift_point\n",
    "#             action, _ = model.predict(obs, deterministic=True)\n",
    "            \n",
    "#             # Keep Gripper Closed (safety override)\n",
    "#             if action[3] > 0: action[3] = -1.0\n",
    "            \n",
    "#             # Check height\n",
    "#             obj_z = obs['observation'][5]\n",
    "#             if obj_z > lift_point[2] - 0.05:\n",
    "#                 print(\">> Lift Complete. Moving to Target...\")\n",
    "#                 state = \"MOVE\"\n",
    "\n",
    "#         elif state == \"MOVE\":\n",
    "#             # Set the Final Target\n",
    "#             obs['desired_goal'] = final_target\n",
    "#             action, _ = model.predict(obs, deterministic=True)\n",
    "            \n",
    "#             # Keep Gripper Closed until very close\n",
    "#             dist_to_target = np.linalg.norm(obs['achieved_goal'] - final_target)\n",
    "#             if dist_to_target > 0.05:\n",
    "#                 if action[3] > 0: action[3] = -1.0\n",
    "            \n",
    "#             # Success Check\n",
    "#             info = env.get_wrapper_attr(\"compute_reward\")(obs['achieved_goal'], final_target, {})\n",
    "#             # Note: reward is usually -1 or 0. Success is 0.\n",
    "#             if dist_to_target < 0.05:\n",
    "#                 print(\">> MISSION COMPLETE\")\n",
    "#                 break\n",
    "        \n",
    "#         # --- EXECUTE STEP ---\n",
    "#         obs, reward, done, info = env.step(action)\n",
    "#         time.sleep(0.05) # Slow down for visualization\n",
    "#         env.render()\n",
    "        \n",
    "#         if done:\n",
    "#             break\n",
    "\n",
    "# # --- USAGE ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee952ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6088694  -0.28861788 -0.05878199]\n",
      "--- Starting Sequence for Object  ---\n",
      "dist:0.7434815168380737 ; grip_pos: [-0.02822911 -0.0232845  -0.13531129] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.9194920063018799 ; grip_pos: [-0.23844746  0.06065339  0.06685882] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.7129766345024109 ; grip_pos: [-0.05906625 -0.1180447  -0.04072295] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.49186351895332336 ; grip_pos: [ 0.16640362 -0.18366925 -0.04623748] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.3035851716995239 ; grip_pos: [ 0.3872642  -0.27144578 -0.06556741] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.3641887307167053 ; grip_pos: [ 0.5989419  -0.2575634  -0.22150846] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.5343226194381714 ; grip_pos: [ 0.604176   -0.22332798 -0.38907984] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.45727968215942383 ; grip_pos: [ 0.51227134 -0.20915245 -0.29862145] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.5912269353866577 ; grip_pos: [ 0.48296273 -0.222363   -0.43263483] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.8040167093276978 ; grip_pos: [ 0.49512312 -0.16991404 -0.6458106 ] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.6041796207427979 ; grip_pos: [ 0.48039284 -0.20114702 -0.44262752] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.41791513562202454 ; grip_pos: [ 0.35828435 -0.29226777 -0.19321716] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.3389138877391815 ; grip_pos: [ 0.2942462  -0.31417564  0.01784186] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.3688483238220215 ; grip_pos: [ 0.32402298 -0.28814125 -0.09311375] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.4076548218727112 ; grip_pos: [ 0.5179196  -0.26575807 -0.2555036 ] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.5699809193611145 ; grip_pos: [ 0.6078225  -0.2124691  -0.42365235] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.48637309670448303 ; grip_pos: [ 0.57168394 -0.17649953 -0.33059284] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.26068776845932007 ; grip_pos: [ 0.5186686  -0.21586029 -0.09229486] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.22375038266181946 ; grip_pos: [ 0.49430355 -0.24644905 -0.04629383] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.43087702989578247 ; grip_pos: [ 0.5022245  -0.28816465 -0.27625257] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.6633347868919373 ; grip_pos: [ 0.5130513 -0.196838  -0.5087115] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.48044002056121826 ; grip_pos: [ 0.50361323 -0.16226766 -0.3102013 ] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.26800188422203064 ; grip_pos: [ 0.43910393 -0.24048792 -0.06049518] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.2770584225654602 ; grip_pos: [ 0.4113424  -0.27213946 -0.05236123] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.4468208849430084 ; grip_pos: [ 0.47718227 -0.28882256 -0.28575665] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.6415460705757141 ; grip_pos: [ 0.535926   -0.17650265 -0.48622984] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.4728304147720337 ; grip_pos: [ 0.53066134 -0.11962094 -0.29339918] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.23335310816764832 ; grip_pos: [ 0.4939377  -0.2063622  -0.04446554] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.22059616446495056 ; grip_pos: [ 0.47092146 -0.25192398 -0.02696819] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.4171191155910492 ; grip_pos: [ 0.49337062 -0.28292048 -0.25955114] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.6480866074562073 ; grip_pos: [ 0.5174928  -0.17988262 -0.4911135 ] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.4712800681591034 ; grip_pos: [ 0.5050702  -0.14198947 -0.29447767] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.25100043416023254 ; grip_pos: [ 0.4519635  -0.22727928 -0.04484472] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.25797736644744873 ; grip_pos: [ 0.42684606 -0.26669872 -0.04027406] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.43392515182495117 ; grip_pos: [ 0.48346692 -0.28430712 -0.2741694 ] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.6443504095077515 ; grip_pos: [ 0.5330096  -0.17134744 -0.48781326] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.47269007563591003 ; grip_pos: [ 0.526944  -0.1243959 -0.2943911] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.2338455766439438 ; grip_pos: [ 0.4888529  -0.21421629 -0.04517994] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.22532369196414948 ; grip_pos: [ 0.46462223 -0.2565868  -0.02889236] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.4189387559890747 ; grip_pos: [ 0.49404168 -0.2834202  -0.26164332] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.6477468013763428 ; grip_pos: [ 0.5224636 -0.1774599 -0.4910429] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.4709022343158722 ; grip_pos: [ 0.5101513  -0.13756737 -0.29373875] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.24509604275226593 ; grip_pos: [ 0.46182385 -0.22428718 -0.04401493] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.24953308701515198 ; grip_pos: [ 0.43672612 -0.26367915 -0.03769962] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.43002456426620483 ; grip_pos: [ 0.48816058 -0.28337705 -0.27148414] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.6454160213470459 ; grip_pos: [ 0.53271705 -0.1737816  -0.48931772] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.47229012846946716 ; grip_pos: [ 0.5246596  -0.12864438 -0.29510197] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.2376905381679535 ; grip_pos: [ 0.48189774 -0.21513455 -0.04579854] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.23306068778038025 ; grip_pos: [ 0.45756093 -0.25760746 -0.0333139 ] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n",
      "dist:0.4238702952861786 ; grip_pos: [ 0.49298933 -0.28289974 -0.26646462] ; hover: [ 0.6088694  -0.28861788  0.14121802]\n"
     ]
    }
   ],
   "source": [
    "# target_pos = np.array([1.43710006, 0.89503746, 0.42489224]) # Final shelf location\n",
    "# run_surgical_pick_and_place(eval_env, model, final_target=target_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f71b62e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35da14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RobotCurriculum():\n",
    "#     def __init__(self, env, model, ):\n",
    "#         self.env = env\n",
    "#         self.model = model\n",
    "#         self.current_obs = None\n",
    "        \n",
    "#     def get_current_obs(self):\n",
    "#         \"\"\" for getting current observation \"\"\"\n",
    "#         return self.current_obs\n",
    "    \n",
    "#     def hover_free(self, hover_point):\n",
    "        \n",
    "#         modified_obs = self.current_obs.copy()\n",
    "#         modified_obs['observations'] = self.current_obs['observations'].copy\n",
    "        \n",
    "#         current_gripper = self.current_obs['observations']\n",
    "        \n",
    "#         assert isinstance(hover_point, np.ndarray) and hover_point.shape == (3,)\n",
    "#         modified_obs[3:6] = hover_point\n",
    "        \n",
    "#         modified_obs[6:9] = hover_point - current_gripper\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac52831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import time\n",
    "\n",
    "# def surgical_routine(vec_env, model, final_target, active_obj_idx, reset_env=False):\n",
    "#     \"\"\"\n",
    "#     Executes a Pick-and-Place operation on the specified object index.\n",
    "#     Includes: Hover -> Grasp -> Lift -> Move -> Place -> Retract.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # 1. HANDLE RESET & TIMER\n",
    "#     if reset_env:\n",
    "#         # Full Reset (Only do this for the VERY FIRST move)\n",
    "#         vec_env.reset()\n",
    "#     else:\n",
    "#         # MAGIC HACK: Reset the hidden \"Time Limit\" counter\n",
    "#         # This prevents the environment from auto-resetting in the middle of your swap\n",
    "#         current_env = vec_env.envs[0]\n",
    "#         while hasattr(current_env, \"env\"):\n",
    "#             if hasattr(current_env, \"_elapsed_steps\"):\n",
    "#                 current_env._elapsed_steps = 0 # Reset the timer to 0\n",
    "#             current_env = current_env.env\n",
    "    \n",
    "#     # 1. Access Wrapper\n",
    "#     env_stack = vec_env.envs[0]\n",
    "#     wrapper = env_stack\n",
    "#     while not hasattr(wrapper, \"set_active_object\"):\n",
    "#         if hasattr(wrapper, \"env\"):\n",
    "#             wrapper = wrapper.env\n",
    "#         else:\n",
    "#             raise ValueError(\"ActiveObjectWrapper not found in env stack!\")\n",
    "            \n",
    "#     # 2. Activate Target Object\n",
    "#     wrapper.set_active_object(active_obj_idx)\n",
    "    \n",
    "#     # 3. Optional Reset (Only for the very first move)\n",
    "#     # if reset_env:\n",
    "#     #     vec_env.reset()\n",
    "    \n",
    "#     # --- SETUP ---\n",
    "#     # Get fresh observation via wrapper\n",
    "#     raw_obs = wrapper.get_current_obs()\n",
    "    \n",
    "#     # Start Position\n",
    "#     obj_pos_start = raw_obs['observation'][3:6].copy()\n",
    "    \n",
    "#     # Calculated Waypoints\n",
    "#     hover_point = obj_pos_start.copy()\n",
    "#     hover_point[2] += 0.10  # 15cm above object\n",
    "    \n",
    "#     SAFE_Z_HEIGHT = 0.65\n",
    "    \n",
    "#     state = \"HOVER\"\n",
    "#     override_gripper = 1.0 # Open\n",
    "    \n",
    "#     print(f\"\\n--- Moving Object {active_obj_idx} ---\")\n",
    "    \n",
    "#     # Loop until complete\n",
    "#     while True:\n",
    "#         # A. READ REALITY\n",
    "#         raw_obs = wrapper.get_current_obs()\n",
    "#         current_grip = raw_obs['observation'][:3]\n",
    "#         current_obj  = raw_obs['observation'][3:6]\n",
    "        \n",
    "#         # B. STATE MACHINE\n",
    "#         if state == \"HOVER\":\n",
    "#             # Goal: Hover point\n",
    "#             # Trick: Ghost Object at Hover\n",
    "#             raw_obs['observation'][3:6] = hover_point\n",
    "#             raw_obs['observation'][6:9] = hover_point - current_grip\n",
    "#             raw_obs['desired_goal'] = hover_point\n",
    "#             override_gripper = 1.0\n",
    "            \n",
    "#             if np.linalg.norm(current_grip - hover_point) < 0.05:\n",
    "#                 state = \"DESCEND\"\n",
    "\n",
    "#         elif state == \"DESCEND\":\n",
    "#             # Goal: Real Object\n",
    "#             raw_obs['desired_goal'] = obj_pos_start\n",
    "#             override_gripper = 1.0\n",
    "            \n",
    "#             if np.linalg.norm(current_grip - obj_pos_start) < 0.03:\n",
    "#                 state = \"GRASP\"\n",
    "\n",
    "#         elif state == \"GRASP\":\n",
    "#             # Goal: Hold\n",
    "#             override_gripper = -1.0 # Close\n",
    "            \n",
    "#             # Trick: \"I have it\"\n",
    "#             raw_obs['observation'][3:6] = current_grip\n",
    "#             raw_obs['observation'][6:9] = [0,0,0]\n",
    "#             raw_obs['desired_goal'] = current_grip # Stay put\n",
    "            \n",
    "#             # Simple timer or check for closure could go here\n",
    "#             # We assume instant grasp and move to lift\n",
    "#             state = \"LIFT\"\n",
    "\n",
    "#         elif state == \"LIFT\":\n",
    "#             # Goal: Elevator Up\n",
    "#             # Trick: \"I have it\"\n",
    "#             raw_obs['observation'][3:6] = current_grip\n",
    "#             raw_obs['observation'][6:9] = [0,0,0]\n",
    "            \n",
    "#             elevator_target = current_grip.copy()\n",
    "#             elevator_target[2] = SAFE_Z_HEIGHT\n",
    "#             raw_obs['desired_goal'] = elevator_target\n",
    "            \n",
    "#             override_gripper = -1.0 # Keep Closed!\n",
    "            \n",
    "#             if current_grip[2] > SAFE_Z_HEIGHT - 0.05:\n",
    "#                 state = \"MOVE\"\n",
    "\n",
    "#         elif state == \"MOVE\":\n",
    "#             # Goal: Final Target\n",
    "#             # Trick: \"I have it\"\n",
    "#             raw_obs['observation'][3:6] = current_grip\n",
    "#             raw_obs['observation'][6:9] = [0,0,0]\n",
    "            \n",
    "#             # Modify target Z to be slightly above table to avoid smashing\n",
    "#             place_target = final_target.copy()\n",
    "#             place_target[2] = max(place_target[2], 0.45) \n",
    "            \n",
    "#             raw_obs['desired_goal'] = place_target\n",
    "#             override_gripper = -1.0\n",
    "            \n",
    "#             # Check 2D distance (XY) mostly, Z can be approximate\n",
    "#             dist_xy = np.linalg.norm(current_obj[:2] - place_target[:2])\n",
    "#             if dist_xy < 0.04:\n",
    "#                 print(\">> Target Reached. Placing...\")\n",
    "#                 state = \"PLACE\"\n",
    "\n",
    "#         elif state == \"PLACE\":\n",
    "#             # Goal: Stay put, Open Gripper\n",
    "#             raw_obs['desired_goal'] = current_grip\n",
    "#             override_gripper = 1.0 # OPEN!\n",
    "            \n",
    "#             # Wait for object to detach (simple logic: just wait a few frames)\n",
    "#             # or check if we can move up\n",
    "#             state = \"RETRACT\"\n",
    "\n",
    "#         elif state == \"RETRACT\":\n",
    "#             # Goal: Go UP to Safe Height again\n",
    "#             # Real Object stays on table, we leave it.\n",
    "            \n",
    "#             retract_target = current_grip.copy()\n",
    "#             retract_target[2] = SAFE_Z_HEIGHT\n",
    "            \n",
    "#             raw_obs['desired_goal'] = retract_target\n",
    "#             override_gripper = 1.0 # Keep Open\n",
    "            \n",
    "#             if current_grip[2] > SAFE_Z_HEIGHT - 0.05:\n",
    "#                 print(\">> Operation Complete.\")\n",
    "#                 return # EXIT FUNCTION\n",
    "\n",
    "#         # C. NORMALIZE & STEP\n",
    "#         obs_vec = {key: val[np.newaxis, ...] for key, val in raw_obs.items()}\n",
    "#         obs_norm = vec_env.normalize_obs(obs_vec)\n",
    "#         action, _ = model.predict(obs_norm, deterministic=True)\n",
    "        \n",
    "#         if override_gripper is not None:\n",
    "#             action[0, 3] = override_gripper\n",
    "\n",
    "#         _, _, done, info = vec_env.step(action)\n",
    "        \n",
    "#         time.sleep(0.02)\n",
    "#         vec_env.render()\n",
    "        \n",
    "#         if done:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38156c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def surgical_routine(vec_env, model, final_target, active_obj_idx, reset_env=False):\n",
    "    \"\"\"\n",
    "    Executes a Pick-and-Place operation on the specified object index.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- FIX 1: FREEZE THE BRAIN ---\n",
    "    # Stop the normalizer from learning from our 'hacked' observations.\n",
    "    # If we don't do this, the running mean/std will drift, making the \n",
    "    # agent fail on the 2nd and 3rd objects.\n",
    "    if hasattr(vec_env, \"training\"):\n",
    "        vec_env.training = False \n",
    "\n",
    "    # --- FIX 2: ROBUST TIMER RESET ---\n",
    "    if reset_env:\n",
    "        print(\">> FULL RESET (Starting fresh)\")\n",
    "        vec_env.reset()\n",
    "    # else:\n",
    "    #     # Recursively hunt for the TimeLimit wrapper and reset it\n",
    "    #     current_env = vec_env.envs[0]\n",
    "    #     timer_found = False\n",
    "    #     while hasattr(current_env, \"env\"):\n",
    "    #         if hasattr(current_env, \"_elapsed_steps\"):\n",
    "    #             current_env._elapsed_steps = 0\n",
    "    #             timer_found = True\n",
    "    #         current_env = current_env.env\n",
    "        \n",
    "    #     if not timer_found:\n",
    "    #         print(\"WARNING: Could not find '_elapsed_steps'. Auto-reset might occur!\")\n",
    "\n",
    "    # 1. Access Wrapper\n",
    "    env_stack = vec_env.envs[0]\n",
    "    wrapper = env_stack\n",
    "    while not hasattr(wrapper, \"set_active_object\"):\n",
    "        if hasattr(wrapper, \"env\"):\n",
    "            wrapper = wrapper.env\n",
    "        else:\n",
    "            raise ValueError(\"ActiveObjectWrapper not found in env stack!\")\n",
    "            \n",
    "    # 2. Activate Target Object\n",
    "    wrapper.set_active_object(active_obj_idx)\n",
    "    \n",
    "    # --- SETUP ---\n",
    "    raw_obs = wrapper.get_current_obs()\n",
    "    obj_pos_start = raw_obs['observation'][3:6].copy()\n",
    "    \n",
    "    # Waypoints\n",
    "    hover_point = obj_pos_start.copy()\n",
    "    hover_point[2] += 0.15  # 15cm above\n",
    "    \n",
    "    SAFE_Z_HEIGHT = 0.65\n",
    "    \n",
    "    state = \"HOVER\"\n",
    "    override_gripper = None\n",
    "    \n",
    "    print(f\"\\n--- Moving Object {active_obj_idx} ---\")\n",
    "    \n",
    "    while True:\n",
    "        # A. READ REALITY\n",
    "        raw_obs = wrapper.get_current_obs()\n",
    "        current_grip = raw_obs['observation'][:3]\n",
    "        current_obj  = raw_obs['observation'][3:6]\n",
    "        \n",
    "        # B. STATE MACHINE\n",
    "        if state == \"HOVER\":\n",
    "            raw_obs['observation'][3:6] = hover_point\n",
    "            raw_obs['observation'][6:9] = hover_point - current_grip\n",
    "            raw_obs['desired_goal'] = hover_point\n",
    "            # override_gripper = 1.0\n",
    "            \n",
    "            if np.linalg.norm(current_grip - hover_point) < 0.05:\n",
    "                state = \"DESCEND\"\n",
    "                print(\">> Hover Reached. Descending...\")\n",
    "\n",
    "        elif state == \"DESCEND\":\n",
    "            raw_obs['desired_goal'] = obj_pos_start\n",
    "            # override_gripper = 1.0\n",
    "            \n",
    "            if np.linalg.norm(current_grip - obj_pos_start) < 0.03:\n",
    "                print(\">> In Position. Grasping...\")\n",
    "                state = \"GRASP\"\n",
    "\n",
    "        elif state == \"GRASP\":\n",
    "            # override_gripper = -1.0 # Close\n",
    "            \n",
    "            # Trick: \"I have it\" - prevents panic\n",
    "            # raw_obs['observation'][3:6] = current_grip\n",
    "            # raw_obs['observation'][6:9] = [0,0,0]\n",
    "            # raw_obs['desired_goal'] = current_grip \n",
    "            \n",
    "            if current_obj[2] > obj_pos_start[2] + 0.02:\n",
    "                print(\">> Object Moving! Lifting...\")\n",
    "                state = \"LIFT\"\n",
    "            \n",
    "\n",
    "        elif state == \"LIFT\":\n",
    "            raw_obs['observation'][3:6] = current_grip\n",
    "            raw_obs['observation'][6:9] = [0,0,0]\n",
    "            \n",
    "            elevator_target = current_grip.copy()\n",
    "            elevator_target[2] = SAFE_Z_HEIGHT\n",
    "            raw_obs['desired_goal'] = elevator_target\n",
    "            # override_gripper = -1.0 \n",
    "            \n",
    "            if current_grip[2] > SAFE_Z_HEIGHT - 0.05:\n",
    "                print(f\">> Lifted Safe (Z={current_grip[2]:.2f}). Moving to Target...\")\n",
    "                state = \"MOVE\"\n",
    "\n",
    "        elif state == \"MOVE\":\n",
    "            # raw_obs['observation'][3:6] = current_grip\n",
    "            # raw_obs['observation'][6:9] = [0,0,0]\n",
    "            \n",
    "            # # Ensure target Z is safe (not inside table)\n",
    "            # place_target = final_target.copy()\n",
    "            # place_target[2] = max(place_target[2], 0.45) \n",
    "            \n",
    "            # raw_obs['desired_goal'] = place_target\n",
    "            # override_gripper = -1.0\n",
    "            \n",
    "            # dist_xy = np.linalg.norm(current_obj[:2] - place_target[:2])\n",
    "            # if dist_xy < 0.04:\n",
    "            #     print(\">> Target Reached. Placing...\")\n",
    "            #     state = \"PLACE\"\n",
    "            raw_obs['desired_goal'] = final_target\n",
    "            \n",
    "            dist = np.linalg.norm(current_obj - final_target)\n",
    "            if dist < 0.02:\n",
    "                print(\">> target reached.placing...\")\n",
    "                break\n",
    "\n",
    "        elif state == \"PLACE\":\n",
    "            # raw_obs['desired_goal'] = current_grip\n",
    "            override_gripper = 1.0 # OPEN!\n",
    "            state = \"RETRACT\"\n",
    "\n",
    "        elif state == \"RETRACT\":\n",
    "            retract_target = current_grip.copy()\n",
    "            retract_target[2] = SAFE_Z_HEIGHT\n",
    "            \n",
    "            raw_obs['desired_goal'] = retract_target\n",
    "            override_gripper = 1.0 \n",
    "            \n",
    "            if current_grip[2] >= SAFE_Z_HEIGHT :\n",
    "                print(\">> Operation Complete.\")\n",
    "                return # SUCCESS\n",
    "\n",
    "        # C. NORMALIZE & STEP\n",
    "        obs_vec = {key: val[np.newaxis, ...] for key, val in raw_obs.items()}\n",
    "        obs_norm = vec_env.normalize_obs(obs_vec)\n",
    "        action, _ = model.predict(obs_norm, deterministic=True)\n",
    "        \n",
    "        if override_gripper is not None:\n",
    "            action[0, 3] = override_gripper\n",
    "\n",
    "        _, _, done, info = vec_env.step(action)\n",
    "        \n",
    "        # --- FIX 3: IGNORE 'DONE' ---\n",
    "        # If the environment auto-resets despite our hack, we don't want to break the loop immediately.\n",
    "        # However, if it DOES reset, physics are broken anyway. \n",
    "        # But this prevents a premature exit if 'done' signals success instead of timeout.\n",
    "        if done:\n",
    "            # We don't break here, we trust our state machine to return.\n",
    "            # But if physics reset, the next loops will look weird.\n",
    "            pass\n",
    "        \n",
    "        time.sleep(0.01)\n",
    "        vec_env.render()\n",
    "\n",
    "# The swap_objects function remains the same, \n",
    "# but ensure you use the updated surgical_routine above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f81ee0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plan: A(1) -> Buffer\n",
      "Plan: B(2) -> A's Spot\n",
      "Plan: A(1) -> B's Spot\n",
      "\n",
      "--- Moving Object 1 ---\n",
      ">> Hover Reached. Descending...\n",
      ">> In Position. Grasping...\n",
      ">> Object Moving! Lifting...\n",
      ">> Lifted Safe (Z=0.61). Moving to Target...\n",
      ">> target reached.placing...\n",
      "\n",
      "--- Moving Object 2 ---\n",
      ">> Hover Reached. Descending...\n",
      ">> In Position. Grasping...\n",
      ">> Object Moving! Lifting...\n",
      ">> Lifted Safe (Z=0.62). Moving to Target...\n",
      ">> target reached.placing...\n",
      "\n",
      "--- Moving Object 1 ---\n",
      ">> Hover Reached. Descending...\n",
      ">> In Position. Grasping...\n",
      ">> Object Moving! Lifting...\n",
      ">> Lifted Safe (Z=0.61). Moving to Target...\n",
      ">> target reached.placing...\n",
      "SWAP COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "def swap_objects(vec_env, model, obj_id_A, obj_id_B):\n",
    "    \"\"\"\n",
    "    Swaps Object A and Object B using a buffer position.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Initialization (Reset ONCE here)\n",
    "    vec_env.reset()\n",
    "    \n",
    "    # Access wrapper to read positions\n",
    "    env_stack = vec_env.envs[0]\n",
    "    wrapper = env_stack\n",
    "    while not hasattr(wrapper, \"set_active_object\"):\n",
    "        if hasattr(wrapper, \"env\"):\n",
    "            wrapper = wrapper.env\n",
    "        else:\n",
    "            raise ValueError(\"Wrapper not found\")\n",
    "\n",
    "    # 2. Get Initial Positions\n",
    "    # We must set active object to read its true data correctly using your helper\n",
    "    wrapper.set_active_object(obj_id_A)\n",
    "    pos_A = wrapper.get_current_obs()['observation'][3:6].copy()\n",
    "    \n",
    "    wrapper.set_active_object(obj_id_B)\n",
    "    pos_B = wrapper.get_current_obs()['observation'][3:6].copy()\n",
    "    \n",
    "    # Define Buffer Position (Empty spot on the table)\n",
    "    # Assuming table center is roughly 1.3, 0.75\n",
    "    buffer_pos = np.array([1.40, 0.64, 0.43]) \n",
    "    \n",
    "    print(f\"Plan: A({obj_id_A}) -> Buffer\")\n",
    "    print(f\"Plan: B({obj_id_B}) -> A's Spot\")\n",
    "    print(f\"Plan: A({obj_id_A}) -> B's Spot\")\n",
    "    \n",
    "    # --- STEP 1: Move A to Buffer ---\n",
    "    surgical_routine(\n",
    "        vec_env, model, \n",
    "        final_target=buffer_pos, \n",
    "        active_obj_idx=obj_id_A, \n",
    "        reset_env=False  # Do NOT reset, we just did\n",
    "    )\n",
    "    \n",
    "    # --- STEP 2: Move B to A's old spot ---\n",
    "    surgical_routine(\n",
    "        vec_env, model, \n",
    "        final_target=pos_A, \n",
    "        active_obj_idx=obj_id_B, \n",
    "        reset_env=False\n",
    "    )\n",
    "    \n",
    "    # --- STEP 3: Move A (from Buffer) to B's old spot ---\n",
    "    surgical_routine(\n",
    "        vec_env, model, \n",
    "        final_target=pos_B, \n",
    "        active_obj_idx=obj_id_A, \n",
    "        reset_env=False\n",
    "    )\n",
    "    \n",
    "    print(\"SWAP COMPLETE!\")\n",
    "\n",
    "# --- EXECUTE ---\n",
    "# Swap Object 0 and Object 1\n",
    "swap_objects(eval_env, model, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12702efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac49175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
